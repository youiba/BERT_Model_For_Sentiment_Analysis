{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg7X/g+QJ8Vcw0fz6BJ6CV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youiba/BERT_Model_For_Sentiment_Analysis/blob/main/Bert1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQsQmJmj7nLr",
        "outputId": "b019a44b-9810-468e-e92c-3d6c5146ce24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-yrLe6q4r0E"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import datasets, Model\n",
        "from keras.layers import Dense, Flatten\n",
        "from transformers import BertModel, BertTokenizer, BertConfig, TFAutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train , y_train) , (X_test , y_test) = keras.datasets.imdb.load_data()"
      ],
      "metadata": {
        "id": "PIxeqKGr8BV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_new = X_train[0:100]\n",
        "y_train_new = y_train[0:100]\n",
        "X_test_new = X_test[0:100]\n",
        "y_test_new = y_test[0:100]"
      ],
      "metadata": {
        "id": "9P-HEYVMWMCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tz = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "9uAKpegR8B1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "token_type_ids = []\n",
        "attention_masks = []"
      ],
      "metadata": {
        "id": "e_UAITh-8CPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the sentence\n",
        "for sentence in X_train_new:\n",
        "    encoded = tz.encode_plus(\n",
        "        text=sentence,  # the sentence to be encoded\n",
        "        add_special_tokens=True,  # Add [CLS] and [SEP]\n",
        "        pad_to_max_length=True,  # Add [PAD]s\n",
        "        max_length = 300,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask = True  # Generate the attention mask\n",
        "    )\n",
        "    input_ids.append(encoded['input_ids'])\n",
        "    token_type_ids.append(encoded['token_type_ids'])\n",
        "    attention_masks.append(encoded['attention_mask'])\n"
      ],
      "metadata": {
        "id": "_QLZ53828rTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_new[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQvctR2dplCd",
        "outputId": "47d62670-a37e-4c18-9b20-d2b22c4cc373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZAQQ8yRpVgM",
        "outputId": "9151be57-ce8b-453c-ad4f-7561edb2d3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_dict = keras.datasets.imdb.get_word_index()\n",
        "sent = []\n",
        "for embedding in input_ids[0]:\n",
        "  if embedding == 101:\n",
        "    word = \"[CLS]\"\n",
        "  elif embedding == 102:\n",
        "    word = \"[SEP]\"\n",
        "  else:\n",
        "    if word not in vocab_dict:\n",
        "      word = \"[OOV]\"\n",
        "    else:\n",
        "      word = vocab_dict[embedding]\n",
        "  sent.append(word)\n",
        "print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nMoSIqCCHkq",
        "outputId": "0b248605-fc26-48b4-ef4e-26492ca12870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[SEP]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]', '[OOV]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = np.array(input_ids)\n",
        "token_type_ids = np.array(token_type_ids)\n",
        "attention_masks = np.array(attention_masks)\n",
        "\n",
        "print(input_ids.shape)\n",
        "print(token_type_ids.shape)\n",
        "print(attention_masks.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "selOYFeN8rpj",
        "outputId": "b1e0dcba-6e43-464d-855e-270a19076b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 300)\n",
            "(100, 300)\n",
            "(100, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoint = 'bert-base-cased'\n",
        "#model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
        "max_seq_length = 300\n",
        "input_layer_1 = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "input_layer_2 = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "input_layer_3 = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=True)\n",
        "pooled_output, sequence_output = bert_layer([input_layer_1, input_layer_2, input_layer_3])\n",
        "flattn_lyr = tf.keras.layers.Flatten()(pooled_output)\n",
        "dense_1 = tf.keras.layers.Dense(512, activation=\"relu\")(flattn_lyr)\n",
        "output_layer = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"classification\")(dense_1)"
      ],
      "metadata": {
        "id": "QHloTQqa8sLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(inputs=[input_layer_1, input_layer_2, input_layer_3], outputs=[output_layer])"
      ],
      "metadata": {
        "id": "vzLzbiCr9MPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss= keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "model.compile(optimizer='adam', loss=loss, metrics='Accuracy')"
      ],
      "metadata": {
        "id": "-2sS3Q3m9nNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNY1ceVO9nj5",
        "outputId": "9800adc9-536e-4e75-f0f3-3e4ec1d5c1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 300)]        0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 300, 768)]                'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 768)          0           ['keras_layer[0][0]']            \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 512)          393728      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " classification (Dense)         (None, 2)            1026        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,876,995\n",
            "Trainable params: 109,876,994\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=[input_ids,token_type_ids,attention_masks],\n",
        "          y=y_train_new,\n",
        "          batch_size=16,\n",
        "          epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-hZyXhZ9u9W",
        "outputId": "2c5a9818-bbf5-4304-d977-83cc0028e24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "7/7 [==============================] - 14s 865ms/step - loss: 1.2578 - Accuracy: 0.4800\n",
            "Epoch 2/25\n",
            "7/7 [==============================] - 6s 863ms/step - loss: 0.7232 - Accuracy: 0.4600\n",
            "Epoch 3/25\n",
            "7/7 [==============================] - 6s 868ms/step - loss: 0.7655 - Accuracy: 0.4400\n",
            "Epoch 4/25\n",
            "7/7 [==============================] - 6s 873ms/step - loss: 1.3952 - Accuracy: 0.5600\n",
            "Epoch 5/25\n",
            "7/7 [==============================] - 6s 873ms/step - loss: 1.5628 - Accuracy: 0.5800\n",
            "Epoch 6/25\n",
            "7/7 [==============================] - 6s 878ms/step - loss: 0.8067 - Accuracy: 0.5000\n",
            "Epoch 7/25\n",
            "7/7 [==============================] - 6s 883ms/step - loss: 0.7989 - Accuracy: 0.5200\n",
            "Epoch 8/25\n",
            "7/7 [==============================] - 6s 887ms/step - loss: 5.5308 - Accuracy: 0.5200\n",
            "Epoch 9/25\n",
            "7/7 [==============================] - 6s 888ms/step - loss: 5.3062 - Accuracy: 0.5600\n",
            "Epoch 10/25\n",
            "7/7 [==============================] - 6s 888ms/step - loss: 1.9547 - Accuracy: 0.4600\n",
            "Epoch 11/25\n",
            "7/7 [==============================] - 6s 891ms/step - loss: 1.2651 - Accuracy: 0.5400\n",
            "Epoch 12/25\n",
            "7/7 [==============================] - 6s 893ms/step - loss: 0.8392 - Accuracy: 0.5200\n",
            "Epoch 13/25\n",
            "7/7 [==============================] - 6s 894ms/step - loss: 1.0769 - Accuracy: 0.4400\n",
            "Epoch 14/25\n",
            "7/7 [==============================] - 6s 901ms/step - loss: 0.7549 - Accuracy: 0.4800\n",
            "Epoch 15/25\n",
            "7/7 [==============================] - 6s 905ms/step - loss: 0.7991 - Accuracy: 0.5600\n",
            "Epoch 16/25\n",
            "7/7 [==============================] - 6s 910ms/step - loss: 0.8386 - Accuracy: 0.5000\n",
            "Epoch 17/25\n",
            "7/7 [==============================] - 6s 907ms/step - loss: 0.8541 - Accuracy: 0.5000\n",
            "Epoch 18/25\n",
            "7/7 [==============================] - 6s 910ms/step - loss: 0.8722 - Accuracy: 0.5800\n",
            "Epoch 19/25\n",
            "7/7 [==============================] - 6s 910ms/step - loss: 0.8307 - Accuracy: 0.5400\n",
            "Epoch 20/25\n",
            "7/7 [==============================] - 7s 918ms/step - loss: 0.8730 - Accuracy: 0.5800\n",
            "Epoch 21/25\n",
            "7/7 [==============================] - 7s 924ms/step - loss: 0.9302 - Accuracy: 0.4400\n",
            "Epoch 22/25\n",
            "7/7 [==============================] - 7s 923ms/step - loss: 0.7588 - Accuracy: 0.4200\n",
            "Epoch 23/25\n",
            "7/7 [==============================] - 7s 923ms/step - loss: 0.7189 - Accuracy: 0.6000\n",
            "Epoch 24/25\n",
            "7/7 [==============================] - 7s 922ms/step - loss: 0.7201 - Accuracy: 0.5600\n",
            "Epoch 25/25\n",
            "7/7 [==============================] - 7s 922ms/step - loss: 0.7142 - Accuracy: 0.5200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7c3870c910>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_ids[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGbKtbS5mfuT",
        "outputId": "6b7b32bf-5b5e-4bf3-ec50-d51db756b294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  101     1   194  1153   194  8255    78   228     5     6  1463  4369\n",
            "  5012   134    26     4   715     8   118  1634    14   394    20    13\n",
            "   119   954   189   102     5   207   110  3103    21    14    69   188\n",
            "     8    30    23     7     4   249   126    93     4   114     9  2300\n",
            "  1523     5   647     4   116     9    35  8163     4   229     9   340\n",
            "  1322     4   118     9     4   130  4901    19     4  1002     5    89\n",
            "    29   952    46    37     4   455     9    45    43    38  1543  1905\n",
            "   398     4  1649    26  6853     5   163    11  3215 10156     4  1153\n",
            "     9   194   775     7  8255 11596   349  2637   148   605 15358  8003\n",
            "    15   123   125    68 23141  6853    15   349   165  4362    98     5\n",
            "     4   228     9    43 36893  1157    15   299   120     5   120   174\n",
            "    11   220   175   136    50     9  4373   228  8255     5 25249   656\n",
            "   245  2350     5     4  9837   131   152   491    18 46151    32  7464\n",
            "  1212    14     9     6   371    78    22   625    64  1382     9     8\n",
            "   168   145    23     4  1690    15    16     4  1355     5    28     6\n",
            "    52   154   462    33    89    78   285    16   145    95   102     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate([input_ids,token_type_ids,attention_masks], y_test_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tSJTz0NMv5Q",
        "outputId": "34f2c2e8-21e5-4c2c-acc8-80909fb01485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 470ms/step - loss: 0.6948 - Accuracy: 0.5300\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.694765567779541, 0.5299999713897705]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([input_ids,token_type_ids,attention_masks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbbhMa9aMv2j",
        "outputId": "1434cb86-5c81-4c6b-bd3a-48a15a8c1ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 2s 678ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.4289328 , 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.4289328 , 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893293, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.4289329 , 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893288, 0.5710671 ],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893282, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715],\n",
              "       [0.42893285, 0.57106715]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}